{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ddcfc6e3",
   "metadata": {},
   "source": [
    "# Entrenamiento de Modelo con Adam (Adaptive Moment Estimation)\n",
    "\n",
    "Este notebook implementa un modelo de regresión usando **Adam (Adaptive Moment Estimation)** para predecir valores basados en datos de series temporales del archivo `dryer.dat`.\n",
    "\n",
    "## ¿Qué es Adam?\n",
    "\n",
    "Adam es un algoritmo de optimización adaptativo que combina las ideas de **Momentum** y **RMSprop**. Mantiene promedios móviles exponenciales tanto del gradiente (primer momento) como del gradiente al cuadrado (segundo momento), y además incluye corrección de sesgo.\n",
    "\n",
    "### Características clave:\n",
    "- **Combina Momentum + RMSprop**: Lo mejor de ambos mundos\n",
    "- **Corrección de sesgo**: Corrige la inicialización en cero\n",
    "- **Learning rates adaptativos**: Por parámetro\n",
    "- **Muy popular**: El optimizador más usado en deep learning\n",
    "\n",
    "## División de datos:\n",
    "- **70%** - Entrenamiento (Train)\n",
    "- **20%** - Validación (Valid)\n",
    "- **10%** - Prueba (Test)\n",
    "\n",
    "**Importante**: Los datos se dividen de forma secuencial para respetar el orden temporal."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b5a3f6",
   "metadata": {},
   "source": [
    "## 1. Importar Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e6042eff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1eeeed83",
   "metadata": {},
   "source": [
    "## 2. Cargar y Explorar los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "191b5362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cargando datos desde dryer.dat...\n",
      "Datos cargados: 1000 muestras\n",
      "Forma de X: (1000, 1)\n",
      "Forma de y: (1000, 1)\n"
     ]
    }
   ],
   "source": [
    "# Cargar datos desde dryer.dat\n",
    "print(\"Cargando datos desde dryer.dat...\")\n",
    "data = np.loadtxt('dryer.dat')\n",
    "\n",
    "# Separar características (X) y variable objetivo (y)\n",
    "X = data[:, 0].reshape(-1, 1)  # Primera columna como entrada\n",
    "y = data[:, 1].reshape(-1, 1)  # Segunda columna como salida\n",
    "\n",
    "print(f\"Datos cargados: {len(X)} muestras\")\n",
    "print(f\"Forma de X: {X.shape}\")\n",
    "print(f\"Forma de y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd884448",
   "metadata": {},
   "source": [
    "## 3. División Secuencial de los Datos\n",
    "\n",
    "Como son datos de series temporales, NO mezclamos los datos. Mantenemos el orden temporal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3af60df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "División de datos SECUENCIAL (series temporales):\n",
      "Train: 700 muestras (70.0%) - Índices [0:700]\n",
      "Valid: 200 muestras (20.0%) - Índices [700:900]\n",
      "Test:  100 muestras (10.0%) - Índices [900:1000]\n"
     ]
    }
   ],
   "source": [
    "# División de datos SECUENCIAL (para series temporales): 70% train, 20% valid, 10% test\n",
    "# No mezclamos los datos, mantenemos el orden temporal\n",
    "n_samples = len(X)\n",
    "train_end = int(0.7 * n_samples)\n",
    "valid_end = int(0.9 * n_samples)\n",
    "\n",
    "# División secuencial\n",
    "X_train = X[:train_end]\n",
    "y_train = y[:train_end]\n",
    "\n",
    "X_valid = X[train_end:valid_end]\n",
    "y_valid = y[train_end:valid_end]\n",
    "\n",
    "X_test = X[valid_end:]\n",
    "y_test = y[valid_end:]\n",
    "\n",
    "print(f\"\\nDivisión de datos SECUENCIAL (series temporales):\")\n",
    "print(f\"Train: {len(X_train)} muestras ({len(X_train)/len(X)*100:.1f}%) - Índices [0:{train_end}]\")\n",
    "print(f\"Valid: {len(X_valid)} muestras ({len(X_valid)/len(X)*100:.1f}%) - Índices [{train_end}:{valid_end}]\")\n",
    "print(f\"Test:  {len(X_test)} muestras ({len(X_test)/len(X)*100:.1f}%) - Índices [{valid_end}:{n_samples}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11151012",
   "metadata": {},
   "source": [
    "## 4. Normalización/Estandarización de los Datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1918c2f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Datos normalizados exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Normalizar datos usando StandardScaler\n",
    "scaler_X = StandardScaler()\n",
    "scaler_y = StandardScaler()\n",
    "\n",
    "X_train_norm = scaler_X.fit_transform(X_train)\n",
    "X_valid_norm = scaler_X.transform(X_valid)\n",
    "X_test_norm = scaler_X.transform(X_test)\n",
    "\n",
    "y_train_norm = scaler_y.fit_transform(y_train)\n",
    "y_valid_norm = scaler_y.transform(y_valid)\n",
    "y_test_norm = scaler_y.transform(y_test)\n",
    "\n",
    "print(\"Datos normalizados exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "711fed33",
   "metadata": {},
   "source": [
    "## 5. Implementación del Modelo con Adam\n",
    "\n",
    "Implementamos desde cero un modelo de regresión usando **Adam (Adaptive Moment Estimation)**.\n",
    "\n",
    "### Fórmula de Adam:\n",
    "```\n",
    "m_t = β₁ * m_{t-1} + (1-β₁) * ∇L           # Primer momento (momentum)\n",
    "v_t = β₂ * v_{t-1} + (1-β₂) * (∇L)²        # Segundo momento (RMSprop)\n",
    "m̂_t = m_t / (1 - β₁ᵗ)                      # Corrección de sesgo\n",
    "v̂_t = v_t / (1 - β₂ᵗ)                      # Corrección de sesgo\n",
    "θ_t = θ_{t-1} - α * m̂_t / (√v̂_t + ε)\n",
    "```\n",
    "\n",
    "Donde:\n",
    "- `m_t`: promedio móvil del gradiente (momentum)\n",
    "- `v_t`: promedio móvil del gradiente al cuadrado (RMSprop)\n",
    "- `β₁`: típicamente 0.9\n",
    "- `β₂`: típicamente 0.999\n",
    "- `ε`: típicamente 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "898935e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Clase AdamRegressor definida exitosamente\n"
     ]
    }
   ],
   "source": [
    "# Implementación de Adam (Adaptive Moment Estimation)\n",
    "class AdamRegressor:\n",
    "    def __init__(self, learning_rate=0.001, n_epochs=700, batch_size=32, beta1=0.9, beta2=0.999, epsilon=1e-8):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_epochs = n_epochs\n",
    "        self.batch_size = batch_size\n",
    "        self.beta1 = beta1  # Factor de decaimiento para primer momento\n",
    "        self.beta2 = beta2  # Factor de decaimiento para segundo momento\n",
    "        self.epsilon = epsilon\n",
    "        self.weights = None\n",
    "        self.bias = None\n",
    "        self.m_w = None  # Primer momento para pesos (momentum)\n",
    "        self.m_b = None  # Primer momento para bias\n",
    "        self.v_w = None  # Segundo momento para pesos (RMSprop)\n",
    "        self.v_b = None  # Segundo momento para bias\n",
    "        self.t = 0  # Contador de iteraciones (para corrección de sesgo)\n",
    "        self.train_losses = []\n",
    "        self.valid_losses = []\n",
    "        \n",
    "    def _initialize_parameters(self, n_features):\n",
    "        \"\"\"Inicializar pesos, bias y momentos\"\"\"\n",
    "        self.weights = np.random.randn(n_features, 1) * 0.01\n",
    "        self.bias = np.zeros((1, 1))\n",
    "        # Inicializar momentos en cero\n",
    "        self.m_w = np.zeros((n_features, 1))\n",
    "        self.m_b = np.zeros((1, 1))\n",
    "        self.v_w = np.zeros((n_features, 1))\n",
    "        self.v_b = np.zeros((1, 1))\n",
    "        self.t = 0\n",
    "    \n",
    "    def _compute_loss(self, y_true, y_pred):\n",
    "        \"\"\"Calcular MSE (Mean Squared Error)\"\"\"\n",
    "        return np.mean((y_true - y_pred) ** 2)\n",
    "    \n",
    "    def _forward(self, X):\n",
    "        \"\"\"Propagación hacia adelante\"\"\"\n",
    "        return np.dot(X, self.weights) + self.bias\n",
    "    \n",
    "    def _backward(self, X, y_true, y_pred):\n",
    "        \"\"\"Propagación hacia atrás (calcular gradientes)\"\"\"\n",
    "        n_samples = X.shape[0]\n",
    "        dw = (-2/n_samples) * np.dot(X.T, (y_true - y_pred))\n",
    "        db = (-2/n_samples) * np.sum(y_true - y_pred)\n",
    "        return dw, db\n",
    "    \n",
    "    def fit(self, X_train, y_train, X_valid=None, y_valid=None):\n",
    "        \"\"\"Entrenar el modelo usando Adam\"\"\"\n",
    "        n_samples, n_features = X_train.shape\n",
    "        self._initialize_parameters(n_features)\n",
    "        \n",
    "        for epoch in range(self.n_epochs):\n",
    "            X = X_train\n",
    "            Y = y_train\n",
    "            \n",
    "            for i in range(0, n_samples, self.batch_size):\n",
    "                X_batch = X[i:i+self.batch_size]\n",
    "                y_batch = Y[i:i+self.batch_size]\n",
    "                \n",
    "                # Incrementar contador de tiempo\n",
    "                self.t += 1\n",
    "                \n",
    "                # Forward pass\n",
    "                y_pred = self._forward(X_batch)\n",
    "                \n",
    "                # Backward pass\n",
    "                dw, db = self._backward(X_batch, y_batch, y_pred)\n",
    "                \n",
    "                # Actualizar primer momento (promedio móvil del gradiente)\n",
    "                self.m_w = self.beta1 * self.m_w + (1 - self.beta1) * dw\n",
    "                self.m_b = self.beta1 * self.m_b + (1 - self.beta1) * db\n",
    "                \n",
    "                # Actualizar segundo momento (promedio móvil del gradiente al cuadrado)\n",
    "                self.v_w = self.beta2 * self.v_w + (1 - self.beta2) * (dw ** 2)\n",
    "                self.v_b = self.beta2 * self.v_b + (1 - self.beta2) * (db ** 2)\n",
    "                \n",
    "                # Corrección de sesgo\n",
    "                m_w_hat = self.m_w / (1 - self.beta1 ** self.t)\n",
    "                m_b_hat = self.m_b / (1 - self.beta1 ** self.t)\n",
    "                v_w_hat = self.v_w / (1 - self.beta2 ** self.t)\n",
    "                v_b_hat = self.v_b / (1 - self.beta2 ** self.t)\n",
    "                \n",
    "                # Actualizar parámetros\n",
    "                self.weights -= self.learning_rate * m_w_hat / (np.sqrt(v_w_hat) + self.epsilon)\n",
    "                self.bias -= self.learning_rate * m_b_hat / (np.sqrt(v_b_hat) + self.epsilon)\n",
    "            \n",
    "            # Calcular pérdida en train\n",
    "            y_train_pred = self._forward(X_train)\n",
    "            train_loss = self._compute_loss(y_train, y_train_pred)\n",
    "            self.train_losses.append(train_loss)\n",
    "            \n",
    "            # Calcular pérdida en validación\n",
    "            if X_valid is not None and y_valid is not None:\n",
    "                y_valid_pred = self._forward(X_valid)\n",
    "                valid_loss = self._compute_loss(y_valid, y_valid_pred)\n",
    "                self.valid_losses.append(valid_loss)\n",
    "                \n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    print(f\"Época {epoch+1}/{self.n_epochs} - Train Loss: {train_loss:.6f} - Valid Loss: {valid_loss:.6f}\")\n",
    "            else:\n",
    "                if (epoch + 1) % 10 == 0:\n",
    "                    print(f\"Época {epoch+1}/{self.n_epochs} - Train Loss: {train_loss:.6f}\")\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"Hacer predicciones\"\"\"\n",
    "        return self._forward(X)\n",
    "    \n",
    "    def evaluate(self, X, y):\n",
    "        \"\"\"Evaluar el modelo\"\"\"\n",
    "        y_pred = self.predict(X)\n",
    "        mse = self._compute_loss(y, y_pred)\n",
    "        rmse = np.sqrt(mse)\n",
    "        \n",
    "        # R² score\n",
    "        ss_tot = np.sum((y - np.mean(y)) ** 2)\n",
    "        ss_res = np.sum((y - y_pred) ** 2)\n",
    "        r2 = 1 - (ss_res / ss_tot)\n",
    "        \n",
    "        return {'MSE': mse, 'RMSE': rmse, 'R2': r2}\n",
    "\n",
    "print(\"Clase AdamRegressor definida exitosamente\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7467790b",
   "metadata": {},
   "source": [
    "## 6. Entrenar el Modelo con Adam\n",
    "\n",
    "### Hiperparámetros:\n",
    "- **learning_rate**: 0.001\n",
    "- **n_epochs**: 200\n",
    "- **batch_size**: 32\n",
    "- **beta1**: 0.9\n",
    "- **beta2**: 0.999\n",
    "- **epsilon**: 1e-8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c7bba659",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "ENTRENAMIENTO DEL MODELO ADAM\n",
      "============================================================\n",
      "Época 10/200 - Train Loss: 0.977719 - Valid Loss: 0.858644\n",
      "Época 20/200 - Train Loss: 0.972751 - Valid Loss: 0.859865\n",
      "Época 30/200 - Train Loss: 0.971473 - Valid Loss: 0.861639\n",
      "Época 40/200 - Train Loss: 0.971158 - Valid Loss: 0.862771\n",
      "Época 50/200 - Train Loss: 0.971083 - Valid Loss: 0.863358\n",
      "Época 60/200 - Train Loss: 0.971067 - Valid Loss: 0.863630\n",
      "Época 70/200 - Train Loss: 0.971064 - Valid Loss: 0.863745\n",
      "Época 80/200 - Train Loss: 0.971064 - Valid Loss: 0.863786\n",
      "Época 90/200 - Train Loss: 0.971065 - Valid Loss: 0.863797\n",
      "Época 100/200 - Train Loss: 0.971065 - Valid Loss: 0.863795\n",
      "Época 110/200 - Train Loss: 0.971065 - Valid Loss: 0.863790\n",
      "Época 120/200 - Train Loss: 0.971066 - Valid Loss: 0.863785\n",
      "Época 130/200 - Train Loss: 0.971066 - Valid Loss: 0.863781\n",
      "Época 130/200 - Train Loss: 0.971066 - Valid Loss: 0.863781\n",
      "Época 140/200 - Train Loss: 0.971066 - Valid Loss: 0.863778\n",
      "Época 140/200 - Train Loss: 0.971066 - Valid Loss: 0.863778\n",
      "Época 150/200 - Train Loss: 0.971066 - Valid Loss: 0.863776\n",
      "Época 150/200 - Train Loss: 0.971066 - Valid Loss: 0.863776\n",
      "Época 160/200 - Train Loss: 0.971066 - Valid Loss: 0.863774\n",
      "Época 170/200 - Train Loss: 0.971066 - Valid Loss: 0.863773\n",
      "Época 180/200 - Train Loss: 0.971066 - Valid Loss: 0.863772\n",
      "Época 190/200 - Train Loss: 0.971066 - Valid Loss: 0.863772\n",
      "Época 200/200 - Train Loss: 0.971066 - Valid Loss: 0.863771\n",
      "Época 160/200 - Train Loss: 0.971066 - Valid Loss: 0.863774\n",
      "Época 170/200 - Train Loss: 0.971066 - Valid Loss: 0.863773\n",
      "Época 180/200 - Train Loss: 0.971066 - Valid Loss: 0.863772\n",
      "Época 190/200 - Train Loss: 0.971066 - Valid Loss: 0.863772\n",
      "Época 200/200 - Train Loss: 0.971066 - Valid Loss: 0.863771\n"
     ]
    }
   ],
   "source": [
    "# Crear y entrenar el modelo con Adam\n",
    "print(\"=\"*60)\n",
    "print(\"ENTRENAMIENTO DEL MODELO ADAM\")\n",
    "print(\"=\"*60)\n",
    "\n",
    "model = AdamRegressor(learning_rate=0.001, n_epochs=200, batch_size=32, beta1=0.9, beta2=0.999, epsilon=1e-8)\n",
    "model.fit(X_train_norm, y_train_norm, X_valid_norm, y_valid_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c1c7e42",
   "metadata": {},
   "source": [
    "## 7. Evaluación del Modelo\n",
    "\n",
    "### 7.1 Evaluación en Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d9ad931",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUACIÓN EN CONJUNTO DE ENTRENAMIENTO\n",
      "============================================================\n",
      "MSE: 0.971066\n",
      "RMSE: 0.985427\n",
      "R2: 0.028934\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en conjunto de entrenamiento\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUACIÓN EN CONJUNTO DE ENTRENAMIENTO\")\n",
    "print(\"=\"*60)\n",
    "train_metrics = model.evaluate(X_train_norm, y_train_norm)\n",
    "for metric, value in train_metrics.items():\n",
    "    print(f\"{metric}: {value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd908b2",
   "metadata": {},
   "source": [
    "### 7.2 Evaluación en Validación"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0e48e221",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUACIÓN EN CONJUNTO DE VALIDACIÓN\n",
      "============================================================\n",
      "MSE: 0.863771\n",
      "RMSE: 0.929393\n",
      "R2: -0.066524\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en conjunto de validación\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUACIÓN EN CONJUNTO DE VALIDACIÓN\")\n",
    "print(\"=\"*60)\n",
    "valid_metrics = model.evaluate(X_valid_norm, y_valid_norm)\n",
    "for metric, value in valid_metrics.items():\n",
    "    print(f\"{metric}: {value:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e989adde",
   "metadata": {},
   "source": [
    "### 7.3 Evaluación en Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0fea221d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "EVALUACIÓN EN CONJUNTO DE PRUEBA (TEST)\n",
      "============================================================\n",
      "MSE: 0.747634\n",
      "RMSE: 0.864658\n",
      "R2: -0.053959\n"
     ]
    }
   ],
   "source": [
    "# Evaluar en conjunto de prueba\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"EVALUACIÓN EN CONJUNTO DE PRUEBA (TEST)\")\n",
    "print(\"=\"*60)\n",
    "test_metrics = model.evaluate(X_test_norm, y_test_norm)\n",
    "for metric, value in test_metrics.items():\n",
    "    print(f\"{metric}: {value:.6f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
